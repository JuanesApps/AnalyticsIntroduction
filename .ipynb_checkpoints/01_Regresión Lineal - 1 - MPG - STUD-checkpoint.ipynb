{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn import datasets, linear_model #datasets y modelos de aprendizaje automático (ML)\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats #para poder hacer cálculos científicos --> valores p\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargar en un **dataframe** de ***pandas*** un dataset muy utilizado para explicar conceptos de aprendizaje del repositorio de Machine Learning alojado en la Universidad De California en Irvine (UCI), que contiene información acerca de automóviles y su rendimiento en millas por galón (MPG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  model  \\\n",
       "0  18.0        8.0         307.0       130.0  3504.0          12.0   70.0   \n",
       "1  15.0        8.0         350.0       165.0  3693.0          11.5   70.0   \n",
       "2  18.0        8.0         318.0       150.0  3436.0          11.0   70.0   \n",
       "3  16.0        8.0         304.0       150.0  3433.0          12.0   70.0   \n",
       "4  17.0        8.0         302.0       140.0  3449.0          10.5   70.0   \n",
       "\n",
       "   origin                   car_name  \n",
       "0     1.0  chevrolet chevelle malibu  \n",
       "1     1.0          buick skylark 320  \n",
       "2     1.0         plymouth satellite  \n",
       "3     1.0              amc rebel sst  \n",
       "4     1.0                ford torino  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data-original\",\n",
    "                   delim_whitespace = True, header=None,\n",
    "                   names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',\n",
    "                            'model', 'origin', 'car_name'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 406 registros con 9 variables.\n",
    "Vamos a analizar si hay problemas de datos con respecto a valores faltantes y outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>398.0</td>\n",
       "      <td>23.514573</td>\n",
       "      <td>7.815984</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.000</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>406.0</td>\n",
       "      <td>5.475369</td>\n",
       "      <td>1.712160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>406.0</td>\n",
       "      <td>194.779557</td>\n",
       "      <td>104.922458</td>\n",
       "      <td>68.0</td>\n",
       "      <td>105.00</td>\n",
       "      <td>151.0</td>\n",
       "      <td>302.000</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>400.0</td>\n",
       "      <td>105.082500</td>\n",
       "      <td>38.768779</td>\n",
       "      <td>46.0</td>\n",
       "      <td>75.75</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130.000</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>406.0</td>\n",
       "      <td>2979.413793</td>\n",
       "      <td>847.004328</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>2226.50</td>\n",
       "      <td>2822.5</td>\n",
       "      <td>3618.250</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>406.0</td>\n",
       "      <td>15.519704</td>\n",
       "      <td>2.803359</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.70</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.175</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>406.0</td>\n",
       "      <td>75.921182</td>\n",
       "      <td>3.748737</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.000</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>406.0</td>\n",
       "      <td>1.568966</td>\n",
       "      <td>0.797479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min      25%     50%  \\\n",
       "mpg           398.0    23.514573    7.815984     9.0    17.50    23.0   \n",
       "cylinders     406.0     5.475369    1.712160     3.0     4.00     4.0   \n",
       "displacement  406.0   194.779557  104.922458    68.0   105.00   151.0   \n",
       "horsepower    400.0   105.082500   38.768779    46.0    75.75    95.0   \n",
       "weight        406.0  2979.413793  847.004328  1613.0  2226.50  2822.5   \n",
       "acceleration  406.0    15.519704    2.803359     8.0    13.70    15.5   \n",
       "model         406.0    75.921182    3.748737    70.0    73.00    76.0   \n",
       "origin        406.0     1.568966    0.797479     1.0     1.00     1.0   \n",
       "\n",
       "                   75%     max  \n",
       "mpg             29.000    46.6  \n",
       "cylinders        8.000     8.0  \n",
       "displacement   302.000   455.0  \n",
       "horsepower     130.000   230.0  \n",
       "weight        3618.250  5140.0  \n",
       "acceleration    17.175    24.8  \n",
       "model           79.000    82.0  \n",
       "origin           2.000     3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer a primera vista no hay outliers, pero si hay valores faltantes (columna count no es de 406 para todas las variables).\n",
    "\n",
    "Además podemos ver que las escalas de las variables son bastante disparejas, con los valores de peso que van de 1600 a 5100, y los de los cilindros de 3 a 8. Es necesario reescalar los datos para otorgarle la misma importancia a cada variable dentro del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a ver que variables tienen valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 406 entries, 0 to 405\n",
      "Data columns (total 9 columns):\n",
      "mpg             398 non-null float64\n",
      "cylinders       406 non-null float64\n",
      "displacement    406 non-null float64\n",
      "horsepower      400 non-null float64\n",
      "weight          406 non-null float64\n",
      "acceleration    406 non-null float64\n",
      "model           406 non-null float64\n",
      "origin          406 non-null float64\n",
      "car_name        406 non-null object\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 28.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg              True\n",
      "cylinders       False\n",
      "displacement    False\n",
      "horsepower       True\n",
      "weight          False\n",
      "acceleration    False\n",
      "model           False\n",
      "origin          False\n",
      "car_name        False\n",
      "dtype: bool\n",
      "Las columnas que tienen valores faltantes son:  [0 3]\n",
      "y corresponden a:  Index(['mpg', 'horsepower'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(data).any(0)) #el 0 implica cualquier columna, si quisieramos las filas utilizamos 1\n",
    "print(\"Las columnas que tienen valores faltantes son: \",pd.isnull(data).any(0).nonzero()[0])\n",
    "print(\"y corresponden a: \", data.columns[pd.isnull(data).any(0).nonzero()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto mpg como horsepower tienen valores faltantes, pero no son muchos.\n",
    "Hay al menos 8 registros con valores faltantes.\n",
    "\n",
    "Podemos encontrar los índices de las filas con los valores faltantes y eliminarlos del dataset.\n",
    "También podemos directamente eliminarlos con un comando de pandas.\n",
    "Vamos a hacer las dos operaciones.\n",
    "\n",
    "Encontramos entonces los índices con registros incompletos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 14 registros incompletos:  [ 10  11  12  13  14  17  38  39 133 337 343 361 367 382]\n"
     ]
    }
   ],
   "source": [
    "indices = pd.isnull(data).any(1).nonzero()[0]\n",
    "print(\"Hay {} registros incompletos: \".format(len(indices)), indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:  (406, 9)\n",
      "Datos limpios y completos:  (392, 9)\n",
      "Se eliminaron 14 registos\n"
     ]
    }
   ],
   "source": [
    "data2 = data.drop(indices)\n",
    "print(\"Datos originales: \", data.shape)\n",
    "print(\"Datos limpios y completos: \", data2.shape)\n",
    "print(\"Se eliminaron {} registos\".format(data.shape[0] - data2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También lo podemos hacer directamente con **dropna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:  (406, 9)\n",
      "Datos limpios y completos:  (392, 9)\n",
      "Se eliminaron 14 registos\n"
     ]
    }
   ],
   "source": [
    "data2 = data.dropna()\n",
    "print(\"Datos originales: \", data.shape)\n",
    "print(\"Datos limpios y completos: \", data2.shape)\n",
    "print(\"Se eliminaron {} registos\".format(data.shape[0] - data2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje del modelo de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ignorar por ahora el hecho de que las variables no siguen la misma escala. Más adelante nos ocuparemos de ese problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo de regresión lineal que permita obtener *mpg* a partir de algunas (5 de ellas) de las demás variables independientes del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "dep_vars = ['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_data = data[indep_vars]\n",
    "dep_data = data[dep_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un dataframe con los datos de las variables independientes y otro con los de la variable dependiente.\n",
    "\n",
    "Vamos ahora a partir cada dataframe en 2 de manera aleatoria: 67% de los datos se utilizarán para aprender el modelo, y 33 para evaluarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(indep_data, dep_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262, 5)\n",
      "(262, 1)\n",
      "(130, 5)\n",
      "(130, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos todos los datos preparados para lanzar el modelo de regresión lineal a partir de los datos de entrenamiento.\n",
    "Lanzamos el método **fit** que se encarga de encontrar la mejor línea de ajuste, y consultamos los diferentes coeficientes encontrados para las variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estableció que se va a utilizar un modelo de regresión lineal, que por defecto incluye un coeficiente para la intercepción con la ordenada en el origen, y especificamos que deseamos normalizar los datos de las variables predictivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders: -0.2622622212088985\n",
      "displacement: -0.001956299665368273\n",
      "horsepower: -0.05984964007927196\n",
      "weight: -0.004940174279273555\n",
      "acceleration: 0.004033488575202949\n",
      "intercepción: 46.532369302492924\n"
     ]
    }
   ],
   "source": [
    "for var, coef in zip(indep_vars, np.squeeze(regr.coef_)):\n",
    "    print(\"{}: {}\".format(var, coef))\n",
    "print(\"intercepción: {}\".format(np.squeeze(regr.intercept_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a predecir la variable dependiente ajustada según el modelo para los datos de entrenamiento y para los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262, 1)\n",
      "(130, 1)\n"
     ]
    }
   ],
   "source": [
    "train_y_pred = regr.predict(train_x)\n",
    "test_y_pred = regr.predict(test_x)\n",
    "print(train_y_pred.shape)\n",
    "print(test_y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como nos va con las métricas de bondad de ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (train): 17.3145\n",
      "MSE (test) : 19.7149\n",
      "R2  (train): 0.7323\n",
      "R2  (test) : 0.6267\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que la predicción con los datos de entrenamiento nos da mejores resultados que con los datos de aprendizaje: por un lado el MSE es menor y por otro lado el R2 es mayor con el training set.\n",
    "\n",
    "Esto muestra que utilizar el mismo set de datos con el que se entrenó al modelo para evaluarlo causa una subestimación del error del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn no ofrece el cálculo del R2 ajustado (viva Python!), por lo que lo calculamos a mano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 adj (train): 0.7270\n",
      "R2 adj (train): 0.6116\n"
     ]
    }
   ],
   "source": [
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor del R2 ajustado corrige el valor del R2 con respecto a la complejidad dada por el número de variables independientes utilizadas, y permite comparar modelos de diferente número de predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los coeficientes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder establecer la significancia de los coeficientes, es necesario realizar pruebas de hipótesis de los coeficientes de cada variable predictiva, comparándolos contra 0.\n",
    "\n",
    "El problema es que **scikit-learn** no realiza estas pruebas, y no incluye muchas de las métricas (como el R2 ajustado), y hay que utilizar el package **statsmodel** (viva Python!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso es bastante complicado, por lo que es a veces mejor conocer cómo obtener los valores p directamente, por lo que usamos el package **statsmodels**. Este paquete requiere adicionar una constante inicial a los datos predictores (correspondiente al valor del intercepto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     const  cylinders  displacement  horsepower  weight  acceleration\n",
      "376    1.0        4.0         112.0        88.0  2640.0          18.6\n",
      "189    1.0        4.0         107.0        86.0  2464.0          15.5\n",
      "127    1.0        4.0         121.0       112.0  2868.0          15.5\n",
      "316    1.0        4.0          98.0        76.0  2144.0          14.7\n",
      "228    1.0        8.0         305.0       145.0  3880.0          12.5\n"
     ]
    }
   ],
   "source": [
    "train_x2 = sm.add_constant(train_x)\n",
    "print(train_x2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   140.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 10 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>3.89e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:02:52</td>     <th>  Log-Likelihood:    </th> <td> -745.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   262</td>      <th>  AIC:               </th> <td>   1503.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   256</td>      <th>  BIC:               </th> <td>   1524.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   46.5324</td> <td>    3.165</td> <td>   14.703</td> <td> 0.000</td> <td>   40.300</td> <td>   52.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cylinders</th>    <td>   -0.2623</td> <td>    0.509</td> <td>   -0.515</td> <td> 0.607</td> <td>   -1.265</td> <td>    0.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displacement</th> <td>   -0.0020</td> <td>    0.011</td> <td>   -0.176</td> <td> 0.860</td> <td>   -0.024</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>   <td>   -0.0598</td> <td>    0.020</td> <td>   -3.057</td> <td> 0.002</td> <td>   -0.098</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weight</th>       <td>   -0.0049</td> <td>    0.001</td> <td>   -5.150</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acceleration</th> <td>    0.0040</td> <td>    0.148</td> <td>    0.027</td> <td> 0.978</td> <td>   -0.287</td> <td>    0.295</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>28.170</td> <th>  Durbin-Watson:     </th> <td>   2.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  37.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.733</td> <th>  Prob(JB):          </th> <td>7.94e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.126</td> <th>  Cond. No.          </th> <td>3.82e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.82e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.732\n",
       "Model:                            OLS   Adj. R-squared:                  0.727\n",
       "Method:                 Least Squares   F-statistic:                     140.0\n",
       "Date:                Tue, 10 Sep 2019   Prob (F-statistic):           3.89e-71\n",
       "Time:                        15:02:52   Log-Likelihood:                -745.31\n",
       "No. Observations:                 262   AIC:                             1503.\n",
       "Df Residuals:                     256   BIC:                             1524.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           46.5324      3.165     14.703      0.000      40.300      52.765\n",
       "cylinders       -0.2623      0.509     -0.515      0.607      -1.265       0.741\n",
       "displacement    -0.0020      0.011     -0.176      0.860      -0.024       0.020\n",
       "horsepower      -0.0598      0.020     -3.057      0.002      -0.098      -0.021\n",
       "weight          -0.0049      0.001     -5.150      0.000      -0.007      -0.003\n",
       "acceleration     0.0040      0.148      0.027      0.978      -0.287       0.295\n",
       "==============================================================================\n",
       "Omnibus:                       28.170   Durbin-Watson:                   2.162\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.303\n",
       "Skew:                           0.733   Prob(JB):                     7.94e-09\n",
       "Kurtosis:                       4.126   Cond. No.                     3.82e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.82e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloStats = sm.OLS(train_y, train_x2)\n",
    "results = modeloStats.fit();\n",
    "#Consultamos la calidad del modelo a partir de sus estadísticas\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que los parámetros cylinders, displacement y acceleration no son para nada significativos en el modelo.\n",
    "\n",
    "También podemos ver que puede que haya problemas de multicolinearidad, como lo establece la 2a advertencia. Vamos a analizar la correlación entre las variables incluidas en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955308</td>\n",
       "      <td>0.853370</td>\n",
       "      <td>0.894257</td>\n",
       "      <td>-0.528679</td>\n",
       "      <td>-0.790598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>0.955308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893969</td>\n",
       "      <td>0.929472</td>\n",
       "      <td>-0.556061</td>\n",
       "      <td>-0.819177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>0.853370</td>\n",
       "      <td>0.893969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855623</td>\n",
       "      <td>-0.698691</td>\n",
       "      <td>-0.802900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.894257</td>\n",
       "      <td>0.929472</td>\n",
       "      <td>0.855623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.420763</td>\n",
       "      <td>-0.839409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>-0.528679</td>\n",
       "      <td>-0.556061</td>\n",
       "      <td>-0.698691</td>\n",
       "      <td>-0.420763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>-0.790598</td>\n",
       "      <td>-0.819177</td>\n",
       "      <td>-0.802900</td>\n",
       "      <td>-0.839409</td>\n",
       "      <td>0.464144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cylinders  displacement  horsepower    weight  acceleration  \\\n",
       "cylinders      1.000000      0.955308    0.853370  0.894257     -0.528679   \n",
       "displacement   0.955308      1.000000    0.893969  0.929472     -0.556061   \n",
       "horsepower     0.853370      0.893969    1.000000  0.855623     -0.698691   \n",
       "weight         0.894257      0.929472    0.855623  1.000000     -0.420763   \n",
       "acceleration  -0.528679     -0.556061   -0.698691 -0.420763      1.000000   \n",
       "mpg           -0.790598     -0.819177   -0.802900 -0.839409      0.464144   \n",
       "\n",
       "                   mpg  \n",
       "cylinders    -0.790598  \n",
       "displacement -0.819177  \n",
       "horsepower   -0.802900  \n",
       "weight       -0.839409  \n",
       "acceleration  0.464144  \n",
       "mpg           1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la matriz de correlaciones\n",
    "corr = train_x.join(train_y).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff5b4145588>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que *aceleration* está bastante correlacionada con las primeras cuatro variables independientes. Podríamos eliminarla y correr el modelo otra vez, pero vamos a preferir seguir un proceso más organizado de forward stepwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escogencia de variables usando forward stepwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos por escoger como primera variable *weight*, pues es la que tiene la correlación más importante con *mpg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7034711364975179\n"
     ]
    }
   ],
   "source": [
    "train_x2 = train_x[['weight']]\n",
    "train_x2 = sm.add_constant(train_x2)\n",
    "modeloStats = sm.OLS(train_y, train_x2)\n",
    "results = modeloStats.fit();\n",
    "print(results.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos entonces de un modelo que solo incluyendo la variable *weight* obtiene un R2 ajustado de 0.703. Vamos a continuar la búsqueda del mejor modelo siguiendo el heurístico de forward stepwise.\n",
    "\n",
    "**<span style=\"color:red\">Taller:</span>** \n",
    "<span style=\"color:red\">Buscar un mejor modelo intentando diferentes combinaciones de variables predictivas:</span>\n",
    "- <span style=\"color:red\">Utilizar el R2 Ajustado como criterio de evaluación.</span>\n",
    "- <span style=\"color:red\">Agregar las variables predictivas que mejor explican la variable dependiente MPG de manera iterativa utilizando la técnica de **forward stepwise** regression.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "...\n",
    "... TODO\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escogencia de variables usando backward stepwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos por escoger todas la variables para crear un modelo inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x3 = train_x[['weight', 'cylinders', 'displacement', 'horsepower', 'acceleration']]\n",
    "train_x3 = sm.add_constant(train_x3)\n",
    "modeloStats = sm.OLS(train_y, train_x3)\n",
    "results = modeloStats.fit();\n",
    "print(results.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos entonces de un modelo que incluye todas las variables, y que obtiene un R2 ajustado de 0.727. Vamos a continuar la búsqueda del mejor modelo siguiendo el heurístico de backward stepwise.\n",
    "\n",
    "**<span style=\"color:red\">Taller:</span>** \n",
    "<span style=\"color:red\">Buscar un mejor modelo intentando diferentes combinaciones de variables predictivas:</span>\n",
    "- <span style=\"color:red\">Utilizar el R2 Ajustado como criterio de evaluación.</span>\n",
    "- <span style=\"color:red\">Eliminar las variables predictivas que impiden obtener un mejor modelos al agregar ruido, utilizando la técnica de **backward stepwise** regression.</span>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "...\n",
    "... TODO\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización: Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar regularización a partir del modelo de **Ridge** regression.\n",
    "La penalización en este modelo se controla a partir del parámetro alpha en la clase **Ridge** de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación del modelo de regresión lineal vs un ridge regression específico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a volver a entrenar el modelo de regresión lineal simple las 5 variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression(normalize=True)\n",
    "regr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = regr.predict(train_x)\n",
    "test_y_pred = regr.predict(test_x)\n",
    "train_y_pred[0:5]\n",
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))\n",
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (test): %.4f' %r2_aj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a lanzar una regresión Ridge con un valor cualquiera de alpha (0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg = linear_model.Ridge(alpha=0.1, fit_intercept=True, normalize=True)\n",
    "ridgereg.fit(train_x, train_y)\n",
    "\n",
    "train_y_pred = ridgereg.predict(train_x)\n",
    "test_y_pred = ridgereg.predict(test_x)\n",
    "train_y_pred[0:5]\n",
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))\n",
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (test): %.4f' %r2_aj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese como se mejora el score en el conjunto de test.\n",
    "Lo que estamos haciendo es mejorando la generalización del modelo a datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los modelos para diferentes grados de penalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a controlar el parámetro *alpha* que controla el componente de penalización de la complejidad de los modelos de Ridge regression.\n",
    "Se crea un conjunto de valores de *alpha* siguiendo una escala logarítmica que se van a utilizar para analizar como varían los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.logspace(-2, 1, n_alphas)\n",
    "alphas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a recorrer el array de valores de alpha, y vamos a aprender un modelo de Ridge para configuración, guardando en el array *coef* los coeficientes de las variables independientes de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "r2adj_train_vec = []\n",
    "r2adj_test_vec = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a, fit_intercept=True, normalize=True)\n",
    "    ridge.fit(train_x, train_y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    train_y_pred = ridge.predict(train_x)\n",
    "    test_y_pred = ridge.predict(test_x)\n",
    "    r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "    r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "    r2adj_train_vec.append(r2_aj_train)\n",
    "    r2adj_test_vec.append(r2_aj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a plotear los valores de las métricas con respecto al valor del alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(alphas, np.squeeze(coefs))\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.legend(indep_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuáles son las variables mas importantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora analizar los valores de r2 ajustado en los dataset de entrenamiento y test.\n",
    "\n",
    "Creamos un array con los valores de las dos series uno a uno para poder plotearlos al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array(r2adj_train_vec)\n",
    "t1 = t1[:, np.newaxis]\n",
    "print(\"train: \", t1.shape)\n",
    "\n",
    "t2 = np.array(r2adj_test_vec)\n",
    "t2 = t2[:, np.newaxis]\n",
    "print(\"test: \", t2.shape)\n",
    "\n",
    "r2adj_vecs = np.concatenate((t1, t2), axis=1)\n",
    "print(\"concatenación: \", r2adj_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "ax = plt.gca()\n",
    "plt.plot(alphas, r2adj_vecs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2 ajustado')\n",
    "plt.title('R2 ajustado con respecto al alpha')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos que para un valor de alpha por debajo de $10^0=1$, se obtiene el valor máximal de R2 ajustado para el conjunto de test.\n",
    "Vamos a utilizar CV para comparar valores de alpha cercanos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiceMax = np.argmax(r2adj_test_vec)\n",
    "r2Max = r2adj_test_vec[indiceMax]\n",
    "alphaMax = alphas[indiceMax]\n",
    "print(\"El nivel máximo de R2 es {}, y se alcanza con un alpha de {}\".format(r2Max, alphaMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg = linear_model.Ridge(alpha=alphaMax, normalize=True)\n",
    "ridgereg.fit(train_x, train_y)\n",
    "\n",
    "train_y_pred = ridgereg.predict(train_x)\n",
    "test_y_pred = ridgereg.predict(test_x)\n",
    "train_y_pred[0:5]\n",
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))\n",
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (test): %.4f' %r2_aj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización: Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora utilizar la regularización del modelo de Lasso. Utilizamos un valor de alpha específico (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoreg = linear_model.Lasso(alpha=0.1, normalize=True)\n",
    "lassoreg.fit(train_x, train_y)\n",
    "\n",
    "train_y_pred = lassoreg.predict(train_x)\n",
    "test_y_pred = lassoreg.predict(test_x)\n",
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))\n",
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (test): %.4f' %r2_aj_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay variables predictivas que se ignoran con la regresión Lasso (cylinders y acceleration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vamos ahora utilizar la regularización del modelo de Lasso. Utilizamos un valor de alpha específico (1).\n",
    "\n",
    "lassoreg = linear_model.Lasso(alpha=0.1, normalize=True)\n",
    "lassoreg.fit(train_x, train_y)\n",
    "\n",
    "train_y_pred = lassoreg.predict(train_x)\n",
    "test_y_pred = lassoreg.predict(test_x)\n",
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))\n",
    "r2_aj_train = 1 - (1-r2_score(train_y, train_y_pred))*(len(train_y)-1) / (len(train_y) - train_x.shape[1] - 1)\n",
    "print('R2 adj (train): %.4f' %r2_aj_train)\n",
    "r2_aj_test = 1 - (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "print('R2 adj (test): %.4f' %r2_aj_test)\n",
    "\n",
    "lassoreg.coef_\n",
    "\n",
    "train_x.columns\n",
    "\n",
    "Vemos que hay variables predictivas que se ignoran con la regresión Lasso (cylinders y acceleration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Taller:</span>** \n",
    "<span style=\"color:red\">Buscar el mejor modelo de regresión Lasso, intentando diferentes valores de alpha. Utilizar el R2 Ajustado sobre el test set como criterio de evaluación.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "...\n",
    "... TODO\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
